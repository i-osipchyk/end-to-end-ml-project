{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-09T10:40:08.152686Z",
     "start_time": "2024-07-09T10:40:08.150673Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'/Users/ivanosipchyk/dev/studies/end-to-end-ml-project/research'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T10:40:11.849402Z",
     "start_time": "2024-07-09T10:40:11.845122Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T10:40:17.681420Z",
     "start_time": "2024-07-09T10:40:17.678746Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ivanosipchyk/dev/studies/end-to-end-ml-project\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T10:40:45.035307Z",
     "start_time": "2024-07-09T10:40:44.910203Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model_path: Path\n",
    "    all_params: dict\n",
    "    metric_file_name: Path\n",
    "    mlflow_uri: str\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T11:19:18.208729Z",
     "start_time": "2024-07-09T11:19:18.204508Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml, create_directories"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T11:16:42.031485Z",
     "start_time": "2024-07-09T11:16:41.900697Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath=CONFIG_FILE_PATH,\n",
    "            params_filepath=PARAMS_FILE_PATH,\n",
    "            schema_filepath=SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        config = self.config.model_evaluation\n",
    "        params = self.params.SVC\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            model_path=config.model_path,\n",
    "            all_params=params,\n",
    "            metric_file_name=config.metric_file_name,\n",
    "            mlflow_uri='https://dagshub.com/ivan.osipchyk.work/end-to-end-ml-project.mlflow'\n",
    "        )\n",
    "\n",
    "        return model_evaluation_config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T11:22:14.658827Z",
     "start_time": "2024-07-09T11:22:14.654763Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import joblib"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T11:47:33.082847Z",
     "start_time": "2024-07-09T11:47:32.952226Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "from mlProject.utils.common import save_json\n",
    "\n",
    "class ModelEvaluation:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        mlflow.set_tracking_uri(config.mlflow_uri)\n",
    "\n",
    "    def eval_metrics(self, y_true, y_pred):\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, average='weighted')\n",
    "        recall = recall_score(y_true, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        return accuracy, precision, recall, f1\n",
    "\n",
    "    def log_into_mlflow(self):\n",
    "        X_test = pd.read_csv(os.path.join(self.config.data_path, 'x_test.csv'), skiprows=1, header=None)\n",
    "        y_test = pd.read_csv(os.path.join(self.config.data_path, 'y_test.csv'))\n",
    "\n",
    "        model = joblib.load(self.config.model_path)\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            acc, pr, rec, f1 = self.eval_metrics(y_test, y_pred)\n",
    "\n",
    "            # Log metrics to mlflow\n",
    "            mlflow.log_metric('accuracy', acc)\n",
    "            mlflow.log_metric('precision', pr)\n",
    "            mlflow.log_metric('recall', rec)\n",
    "            mlflow.log_metric('f1 score', f1)\n",
    "\n",
    "            # Log parameters to mlflow\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "\n",
    "            # Save metrics to a JSON file using save_json utility\n",
    "            scores = {\n",
    "                'accuracy': acc,\n",
    "                'precision': pr,\n",
    "                'recall': rec,\n",
    "                'f1 score': f1\n",
    "            }\n",
    "            save_json(path=Path(os.path.join(self.config.root_dir, self.config.metric_file_name)), data=scores)\n",
    "\n",
    "            # Log the model to mlflow\n",
    "            tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "            if tracking_url_type_store != \"file\":\n",
    "                mlflow.sklearn.log_model(model, 'model', registered_model_name='SVC')\n",
    "            else:\n",
    "                mlflow.sklearn.log_model(model, \"model\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T12:16:06.687612Z",
     "start_time": "2024-07-09T12:16:06.686549Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-09 14:38:04,734: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-07-09 14:38:04,735: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-07-09 14:38:04,737: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-07-09 14:38:04,738: INFO: common: created directory at: artifacts]\n",
      "[2024-07-09 14:38:04,739: INFO: common: created directory at: artifacts/model_evaluation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanosipchyk/dev/studies/end-to-end-ml-project/venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/ivanosipchyk/dev/studies/end-to-end-ml-project/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-09 14:38:06,521: INFO: common: json file saved at: artifacts/model_evaluation/metrics.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'SVC' already exists. Creating a new version of this model...\n",
      "2024/07/09 14:38:11 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: SVC, version 3\n",
      "Created version '3' of model 'SVC'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_eval_config = config.get_model_evaluation_config()\n",
    "    model_eval_config = ModelEvaluation(config=model_eval_config)\n",
    "    model_eval_config.log_into_mlflow()\n",
    "except Exception as e:\n",
    "    raise e"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T12:38:11.622403Z",
     "start_time": "2024-07-09T12:38:04.737937Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(os.path.join('artifacts/data_transformation', 'x_test.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T11:35:33.630844Z",
     "start_time": "2024-07-09T11:35:33.627011Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n0       2.719067             0.615         0.66        1.837424  -2.340266   \n1       2.473559             0.270         0.24        0.755871  -2.465357   \n2       2.090022             0.735         0.00        0.804206  -2.372742   \n3       2.232275             0.340         0.40        0.894913  -2.554798   \n4       2.607519             0.440         0.64        0.755871  -2.639071   \n\n   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n0             2.043721              4.109736  1.00220  3.07  -0.312246   \n1             2.899951              3.820764  0.99560  3.22  -0.411227   \n2             3.109664              3.625875  0.99765  3.41  -0.504356   \n3             3.444478              4.271245  0.99554  3.34  -0.150254   \n4             1.675968              2.899951  0.99800  3.21  -0.396493   \n\n    alcohol  \n0  2.440369  \n1  2.719067  \n2  2.371051  \n3  2.547564  \n4  2.462599  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.719067</td>\n      <td>0.615</td>\n      <td>0.66</td>\n      <td>1.837424</td>\n      <td>-2.340266</td>\n      <td>2.043721</td>\n      <td>4.109736</td>\n      <td>1.00220</td>\n      <td>3.07</td>\n      <td>-0.312246</td>\n      <td>2.440369</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.473559</td>\n      <td>0.270</td>\n      <td>0.24</td>\n      <td>0.755871</td>\n      <td>-2.465357</td>\n      <td>2.899951</td>\n      <td>3.820764</td>\n      <td>0.99560</td>\n      <td>3.22</td>\n      <td>-0.411227</td>\n      <td>2.719067</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.090022</td>\n      <td>0.735</td>\n      <td>0.00</td>\n      <td>0.804206</td>\n      <td>-2.372742</td>\n      <td>3.109664</td>\n      <td>3.625875</td>\n      <td>0.99765</td>\n      <td>3.41</td>\n      <td>-0.504356</td>\n      <td>2.371051</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.232275</td>\n      <td>0.340</td>\n      <td>0.40</td>\n      <td>0.894913</td>\n      <td>-2.554798</td>\n      <td>3.444478</td>\n      <td>4.271245</td>\n      <td>0.99554</td>\n      <td>3.34</td>\n      <td>-0.150254</td>\n      <td>2.547564</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.607519</td>\n      <td>0.440</td>\n      <td>0.64</td>\n      <td>0.755871</td>\n      <td>-2.639071</td>\n      <td>1.675968</td>\n      <td>2.899951</td>\n      <td>0.99800</td>\n      <td>3.21</td>\n      <td>-0.396493</td>\n      <td>2.462599</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T11:35:41.478511Z",
     "start_time": "2024-07-09T11:35:41.464760Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
